{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"PassengerId\",\"Name\",\"Ticket\"], axis=1)\n",
    "test_df = test_df.drop([\"PassengerId\",\"Name\",\"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "-------\n",
      "Test\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age          86\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          1\n",
      "Cabin       327\n",
      "Embarked      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (\"Train\")\n",
    "print (train_df.isnull().sum() )\n",
    "print (\"-------\")\n",
    "print (\"Test\")\n",
    "print (test_df.isnull().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female mean age: 29\n",
      "male mean age: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simon\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# get mean values per gender\n",
    "male_mean_age = combined_df[combined_df[\"Sex\"]==\"male\"][\"Age\"].mean()\n",
    "female_mean_age = combined_df[combined_df[\"Sex\"]==\"female\"][\"Age\"].mean()\n",
    "print (\"female mean age: %1.0f\" %female_mean_age )\n",
    "print (\"male mean age: %1.0f\" %male_mean_age )\n",
    "\n",
    "# fill the nan values \n",
    "train_df.loc[ (train_df[\"Sex\"]==\"male\") & (train_df[\"Age\"].isnull()), \"Age\"] = male_mean_age\n",
    "train_df.loc[ (train_df[\"Sex\"]==\"female\") & (train_df[\"Age\"].isnull()), \"Age\"] = female_mean_age\n",
    "\n",
    "test_df.loc[ (test_df[\"Sex\"]==\"male\") & (test_df[\"Age\"].isnull()), \"Age\"] = male_mean_age\n",
    "test_df.loc[ (test_df[\"Sex\"]==\"female\") & (test_df[\"Age\"].isnull()), \"Age\"] = female_mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Cabin\"] = train_df[\"Cabin\"].fillna(\"X\")\n",
    "test_df[\"Cabin\"] = test_df[\"Cabin\"].fillna(\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fare = combined_df[\"Fare\"].mean()\n",
    "test_df[\"Fare\"] = test_df[\"Fare\"].fillna(mean_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")\n",
    "test_df[\"Embarked\"] = test_df[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape (713,9)\n",
      "cv set shape (178,9)\n",
      "Check if they have common indexes. The folowing line should be an empty set:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# sampling 80% for train data\n",
    "train_set = train_df.sample(frac=0.8, replace=False, random_state=777)\n",
    "# the other 20% is reserverd for cross validation\n",
    "cv_set = train_df.loc[ set(train_df.index) - set(train_set.index)]\n",
    "\n",
    "print (\"train set shape (%i,%i)\"  %train_set.shape)\n",
    "print (\"cv set shape (%i,%i)\"   %cv_set.shape)\n",
    "print (\"Check if they have common indexes. The folowing line should be an empty set:\")\n",
    "print (set(train_set.index) & set(cv_set.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining numeric columns\n",
    "pclass_feature = tf.feature_column.numeric_column('Pclass')\n",
    "parch_feature = tf.feature_column.numeric_column('Parch')\n",
    "fare_feature = tf.feature_column.numeric_column('Fare')\n",
    "age_feature = tf.feature_column.numeric_column('Age')\n",
    "\n",
    "#defining buckets for children, teens, adults and elders.\n",
    "age_bucket_feature = tf.feature_column.bucketized_column(age_feature,[5,12,18,25,35,60])\n",
    "\n",
    "#defining a categorical column with predefined values\n",
    "sex_feature = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'Sex',['female','male']\n",
    ")\n",
    "#defining a categorical columns with dynamic values\n",
    "embarked_feature =  tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'Embarked', 3 \n",
    ")\n",
    "cabin_feature =  tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'Cabin', 100 \n",
    ")\n",
    "\n",
    "feature_columns = [ pclass_feature,age_feature, age_bucket_feature, parch_feature, \n",
    "                   fare_feature, embarked_feature, cabin_feature ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='Pclass', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _BucketizedColumn(source_column=_NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(5, 12, 18, 25, 35, 60)),\n",
       " _NumericColumn(key='Parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _HashedCategoricalColumn(key='Embarked', hash_bucket_size=3, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='Cabin', hash_bucket_size=100, dtype=tf.string)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Simon\\AppData\\Local\\Temp\\tmpq7dpq4ur\n",
      "INFO:tensorflow:Using config: {'_service': None, '_keep_checkpoint_max': 5, '_session_config': None, '_model_dir': 'C:\\\\Users\\\\Simon\\\\AppData\\\\Local\\\\Temp\\\\tmpq7dpq4ur', '_global_id_in_cluster': 0, '_is_chief': True, '_evaluation_master': '', '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001B6062EFA58>, '_train_distribute': None, '_save_checkpoints_steps': None, '_master': '', '_task_id': 0, '_tf_random_seed': None, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train input function\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=train_set.drop('Survived', axis=1),\n",
    "      y=train_set.Survived,\n",
    "      num_epochs=None, #For training it can use how many epochs is necessary\n",
    "      shuffle=True,\n",
    "      target_column='target',\n",
    ")\n",
    "\n",
    "cv_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=cv_set.drop('Survived', axis=1),\n",
    "      y=cv_set.Survived,\n",
    "      num_epochs=1, #We just want to use one epoch since this is only to score.\n",
    "      shuffle=False  #It isn't necessary to shuffle the cross validation \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Simon\\AppData\\Local\\Temp\\tmpq7dpq4ur\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 88.722855\n",
      "INFO:tensorflow:global_step/sec: 138.484\n",
      "INFO:tensorflow:step = 101, loss = 80.53661 (0.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.826\n",
      "INFO:tensorflow:step = 201, loss = 69.61542 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.835\n",
      "INFO:tensorflow:step = 301, loss = 62.76243 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.835\n",
      "INFO:tensorflow:step = 401, loss = 68.088684 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.128\n",
      "INFO:tensorflow:step = 501, loss = 60.106525 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.6847\n",
      "INFO:tensorflow:step = 601, loss = 70.26138 (1.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.903\n",
      "INFO:tensorflow:step = 701, loss = 67.845566 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.622\n",
      "INFO:tensorflow:step = 801, loss = 68.27595 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.732\n",
      "INFO:tensorflow:step = 901, loss = 63.320198 (0.382 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Simon\\AppData\\Local\\Temp\\tmpq7dpq4ur\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 63.24175.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x1b6062ef710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-27-01:56:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Simon\\AppData\\Local\\Temp\\tmpq7dpq4ur\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-27-01:56:41\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.6966292, accuracy_baseline = 0.6460674, auc = 0.71987575, auc_precision_recall = 0.6013047, average_loss = 0.6092997, global_step = 1000, label/mean = 0.3539326, loss = 54.227673, precision = 0.60465115, prediction/mean = 0.37136105, recall = 0.41269842\n",
      "\n",
      "Test Accuracy: 0.696629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = estimator.evaluate(input_fn=cv_input_fn)\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(scores['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Simon\\AppData\\Local\\Temp\\tmp3pn_ly6o\n",
      "INFO:tensorflow:Using config: {'_service': None, '_keep_checkpoint_max': 5, '_session_config': None, '_model_dir': 'C:\\\\Users\\\\Simon\\\\AppData\\\\Local\\\\Temp\\\\tmp3pn_ly6o', '_global_id_in_cluster': 0, '_is_chief': True, '_evaluation_master': '', '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001B6091F8AC8>, '_train_distribute': None, '_save_checkpoints_steps': None, '_master': '', '_task_id': 0, '_tf_random_seed': None, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Simon\\AppData\\Local\\Temp\\tmp3pn_ly6o\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 86.51469\n",
      "INFO:tensorflow:global_step/sec: 142.009\n",
      "INFO:tensorflow:step = 101, loss = 77.558075 (0.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.487\n",
      "INFO:tensorflow:step = 201, loss = 71.70224 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.293\n",
      "INFO:tensorflow:step = 301, loss = 63.907024 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.891\n",
      "INFO:tensorflow:step = 401, loss = 57.378365 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.956\n",
      "INFO:tensorflow:step = 501, loss = 62.233555 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.984\n",
      "INFO:tensorflow:step = 601, loss = 60.40326 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.915\n",
      "INFO:tensorflow:step = 701, loss = 63.285248 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.166\n",
      "INFO:tensorflow:step = 801, loss = 71.85361 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.367\n",
      "INFO:tensorflow:step = 901, loss = 63.453648 (0.436 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Simon\\AppData\\Local\\Temp\\tmp3pn_ly6o\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 70.56754.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1b6091f8470>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNN doesn't support categorical with hash bucket\n",
    "embarked_embedding =  tf.feature_column.embedding_column(\n",
    "    categorical_column = embarked_feature,\n",
    "    dimension = 3,\n",
    ")\n",
    "cabin_embedding =  tf.feature_column.embedding_column(\n",
    "    categorical_column = cabin_feature,\n",
    "    dimension = 300,\n",
    ")\n",
    "\n",
    "# define the feature columns\n",
    "feature_columns = [ pclass_feature,age_feature, age_bucket_feature, parch_feature, \n",
    "                   fare_feature, embarked_embedding, cabin_embedding ]\n",
    "\n",
    "# instantiate the estimator\n",
    "NNestimator = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[10, 30 , 10])\n",
    "\n",
    "# call the train function using the train input function\n",
    "NNestimator.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-27-01:59:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Simon\\AppData\\Local\\Temp\\tmp3pn_ly6o\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-27-01:59:48\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.71348315, accuracy_baseline = 0.6460674, auc = 0.7446515, auc_precision_recall = 0.6449059, average_loss = 0.73853123, global_step = 1000, label/mean = 0.3539326, loss = 65.72928, precision = 0.64285713, prediction/mean = 0.39738476, recall = 0.42857143\n",
      "\n",
      "Test Accuracy: 0.713483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = NNestimator.evaluate(input_fn=cv_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(df):\n",
    "    df_copy = df[['Pclass', 'Parch',  'Sex', 'Embarked', \"Age\"]].copy()\n",
    "    df_copy.loc[:,\"Sex\"] = df_copy.Sex.apply(lambda x: 0 if x ==\"male\" else 1)\n",
    "\n",
    "    e_map = {\"C\": 0,\"Q\":1, \"S\":2}\n",
    "    df_copy.loc[:,\"Embarked\"] = df_copy.Embarked.apply(lambda x: e_map[x])\n",
    "\n",
    "    df_copy.loc[:,\"Age\"]= df_copy.Age.astype(np.float32)\n",
    "\n",
    "    x = df_copy[['Pclass', 'Parch', 'Age']].astype(np.float32)\n",
    "#     y = train_set.Survived.astype(np.int32)\n",
    "    y = df.Survived.astype(np.bool)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = prepare_datasets(train_set)\n",
    "x_cv, y_cv = prepare_datasets(cv_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tf_input_fn(x_input,y_input,num_epochs=None):\n",
    "    #this is the function we are generating\n",
    "    def _input_fn_():\n",
    "        # generate a standard input function\n",
    "        train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "            x= x_input,  \n",
    "            y= y_input,\n",
    "            num_epochs=num_epochs,\n",
    "            shuffle=True,\n",
    "            target_column='target',\n",
    "        )\n",
    "        #execute the standard input function \n",
    "        x, y = train_input_fn()\n",
    "        # expand the shape of the results (necessary for Tensor Forest)\n",
    "        for name in x:\n",
    "            x[name] = tf.expand_dims(x[name], 1, name= name) \n",
    "        return x, y\n",
    "    \n",
    "    return _input_fn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
